[#start-minikube]
**Configure and Start Minikube**

Before installing Knative and its components, we need to create a Minikube virtual machine and deploy Kubernetes into it.

Download https://kubernetes.io/docs/setup/minikube[minikube] and add it to your path.

[#setup-minikube-start]
[source,bash,subs="+macros,+attributes"]
----
$TUTORIAL_HOME/bin/start-minikube.sh
----
copyToClipboard::setup-minikube-start[]

.Minikube starting
[source,bash,subs="+macros,+attributes"]
----
‚ùå  profile "{tutorial-namespace}" not found
‚úÖ  Created a new profile : {tutorial-namespace}
‚úÖ  minikube profile was successfully set to {tutorial-namespace}
üòÑ  [{tutorial-namespace}] minikube v1.6.2 on Darwin 10.15.2
‚ú®  Selecting 'virtualbox' driver from user configuration (alternates: [hyperkit])
üî•  Creating virtualbox VM (CPUs=4, Memory=8192MB, Disk=50000MB) ...
üê≥  Preparing Kubernetes v1.14.0 on Docker '19.03.5' ...
    ‚ñ™ apiserver.enable-admission-plugins=LimitRanger,NamespaceExists,NamespaceLifecycle,ResourceQuota,ServiceAccount,DefaultStorageClass,MutatingAdmissionWebhook
üöú  Pulling images ...
üöÄ  Launching Kubernetes ...
‚åõ  Waiting for cluster to come online ...
üèÑ  Done! kubectl is now configured to use "{tutorial-namespace}"
----

[#minikube-enable-registry]
**Enable Internal Registry**

[#minikube-enable-registry-run]
[source,bash,subs="+macros,attributes+"]
----
minikube addons enable registry
----
copyToClipboard::minikube-enable-registry-run[]

NOTE: It will take few mins for the registry to be enabled, you can watch the status using `kubectl get pods -n kube-system -w  | grep registry`

A successful enable of <<minikube-enable-registry,registry>> will show the following pods when running the command:

[#minikube-check-registry]
[source,bash,subs="attributes+,+macros"]
----
kubectl get pods -n kube-system | grep registry
----
copyToClipboard::minikube-check-registry[]

[source,bash]
----
registry-7c5hg                             1/1     Running   0          29m
registry-proxy-cj6dj                       1/1     Running   0          29m
----

**Navigate to registry helper folder:**

[#minikube-registry-helper-nav]
[source,bash,subs="attributes+,+macros"]
----
cd $TUTORIAL_HOME/apps/minikube-registry-helper
----
copyToClipboard::minikube-registry-helper-nav[]

**Deploy Registry Helper**

As part of some exercises in the tutorial, we need to push and pull images to local internal registry. To make push and pull smoother we will have a helper deployed so that we can use some common names like `dev.local`, `example.com` as registry aliases for internal registry

**Add entries to minikube host file**

[#minikube-add-entry-to-host]
[source,bash,subs="attributes+,+macros"]
----
kubectl apply -n kube-system -f registry-aliases-config.yaml &&\
kubectl apply -n kube-system -f node-etc-hosts-update.yaml
----
copyToClipboard::minikube-add-entry-to-host[]

[IMPORTANT]
=====
Wait for the Daemonset to be running before proceeding to next step, the status of the Daemonset can be viewed via `kubectl get pods -n kube-system -w`, you can do kbd:[CTRL+c] to end the watch.
=====

Check if the entries are added to minikube node host file

[#minikube-check-host-entry]
[source,bash,subs="attributes+,+macros"]
----
watch minikube ssh -- sudo cat /etc/hosts
----
copyToClipboard::minikube-check-host-entry[]

A successful daemonset run will show the minikube node `/etc/hosts` file with the following entries:

[source,bash]
----
127.0.0.1       localhost
127.0.1.1 demo
10.111.151.121  dev.local
10.111.151.121  example.com
----

[NOTE]
======
The IP for `dev.local` and `example.com` will match the **CLUSTER-IP** of the internal registry. To know the Cluster IP run the command:

[#minikube-check-registry-ip]
[source,bash,subs="attributes+,+macros"]
----
kubectl get svc registry -n kube-system
----
copyToClipboard::minikube-check-registry-ip[]
======

[source,bash,subs="attributes+,+macros"]
----
NAME       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE
registry   ClusterIP   10.111.151.121   <none>        80/TCP                  178m
----

**Update CoreDNS**

[#minikube-update-coredns]
[source,bash,subs="attributes+,+macros"]
----
./patch-coredns.sh
----
copyToClipboard::minikube-update-coredns[]

To check successful patch  run the following command 

[#check-coredns-cm]
[source,bash,subs="attributes+,+macros"]
----
kubectl get cm -n kube-system coredns -o yaml
----
copyToClipboard::check-coredns-cm[]

A successful patch will have the coredns updated ConfigMap `coredns` in `kube-system`

[source,yaml]
----
apiVersion: v1
data:
  Corefile: |-
    .:53 {
        errors
        health
        rewrite name dev.local registry.kube-system.svc.cluster.local
        rewrite name example.com registry.kube-system.svc.cluster.local
        kubernetes cluster.local in-addr.arpa ip6.arpa {
           pods insecure
           upstream
           fallthrough in-addr.arpa ip6.arpa
        }
        prometheus :9153
        proxy . /etc/resolv.conf
        cache 30
        loop
        reload
        loadbalance
    }
kind: ConfigMap
metadata:
  name: coredns
----

**Install Custom Resource Definitions**

[#run-knative-crd-install]
[source,bash,subs="+macros,+attributes"]
----
kubectl apply --selector knative.dev/crd-install=true \
  --filename {knative-serving-repo}/{knative-serving-version}/serving-crds.yaml \
  --filename {knative-eventing-repo}/{knative-eventing-version}/eventing.yaml
----
copyToClipboard::run-knative-crd-install[]

Now that you have installed the Knative Serving and Eventing CRDs, the following sections we will verify the CRDs by querying the `api-resources`.

All *Knative Serving* resources will be under the API group called `serving.knative.dev`.

.serving.knative.dev

[source,bash,subs="+quotes,+attributes,+macros"]
----
kubectl api-resources --api-group='serving.knative.dev'
----

[source,bash,subs="+quotes,+attributes,+macros"]
----
NAME             SHORTNAMES      APIGROUP              NAMESPACED   KIND
configurations   config,cfg      serving.knative.dev   true         Configuration
revisions        rev             serving.knative.dev   true         Revision
routes           rt              serving.knative.dev   true         Route
services         kservice,ksvc   serving.knative.dev   true         Service
----

All *Knative Eventing* resources will be under the one of following API groups:

 - messaging.knative.dev
 - eventing.knative.dev
 - sources.eventing.knative.dev
 - sources.knative.dev

.messaging.knative.dev
[source,bash,subs="+quotes,+attributes,+macros"]
----
kubectl api-resources --api-group='messaging.knative.dev'
----

[source,bash,subs="+quotes,+attributes,+macros"]
----
NAME               SHORTNAMES   APIGROUP                NAMESPACED   KIND
channels           ch           messaging.knative.dev   true         Channel
inmemorychannels   imc          messaging.knative.dev   true         InMemoryChannel
parallels                       messaging.knative.dev   true         Parallel
sequences                       messaging.knative.dev   true         Sequence
subscriptions      sub          messaging.knative.dev   true         Subscription
----

.eventing.knative.dev
[source,bash,subs="+quotes,+attributes,+macros"]
----
kubectl api-resources --api-group='eventing.knative.dev'
----

[source,bash,subs="+quotes,+attributes,+macros"]
----
NAME         SHORTNAMES   APIGROUP               NAMESPACED   KIND
brokers                   eventing.knative.dev   true         Broker
eventtypes                eventing.knative.dev   true         EventType
triggers                  eventing.knative.dev   true         Trigger
----

.sources.eventing.knative.dev
[source,bash,subs="+quotes,+attributes,+macros"]
----
kubectl api-resources --api-group='sources.eventing.knative.dev'
----

[source,bash,subs="+quotes,+attributes,+macros"]
----
NAME               SHORTNAMES   APIGROUP                       NAMESPACED   KIND
apiserversources                sources.eventing.knative.dev   true         ApiServerSource
containersources                sources.eventing.knative.dev   true         ContainerSource
cronjobsources                  sources.eventing.knative.dev   true         CronJobSource
sinkbindings                    sources.eventing.knative.dev   true         SinkBinding
----

.sources.knative.dev
[source,bash,subs="+quotes,+attributes,+macros"]
----
kubectl api-resources --api-group='sources.knative.dev'
----

[source,bash,subs="+quotes,+attributes,+macros"]
----
NAME               SHORTNAMES   APIGROUP              NAMESPACED   KIND
apiserversources                sources.knative.dev   true         ApiServerSource
sinkbindings                    sources.knative.dev   true         SinkBinding
----

The Knative has two main infrastructure components: https://kubernetes.io/docs/concepts/architecture/controller/[controller] and https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/[webhook] helps in translating the Knative CRDs which are usually written YAML files, into Kubernetes objects like Deployment and Service. Apart from the controller and webhook, the Knative Serving and Eventing also install their respective functional components which are listed in the upcoming sections.

**Install Knative Serving**

[#run-install-knative-serving]
[source,bash,subs="+macros,+attributes"]
----
kubectl apply \
  --filename \
  {knative-serving-repo}/{knative-serving-version}/serving-core.yaml
----
copyToClipboard::run-install-knative-serving[]

This process will take few minutes for the Knative Serving pods to be up and running, you can monitor the status of the Knative Serving installation by watching the pods in the `knative-serving` namespace, using the command:

.Knative Serving pods
[source,bash,subs="+quotes,+attributes,+macros"]
----
watch kubectl get pods -n knative-serving
----

[source,bash,subs="+quotes,+attributes,+macros"]
----
NAME                          READY   STATUS    RESTARTS   AGE
activator-6b49796b46-g66z2    1/1     Running   0          11m
autoscaler-7b46fcb475-cnbrm   1/1     Running   0          11m
controller-65f4f4bcb4-mrkgs   1/1     Running   0          11m
webhook-59585cb6-wqldc        1/1     Running   0          11m
----

*Install Kourier*

[#run-install-kourier]
[source,bash,subs="+macros,+attributes"]
----
kubectl apply \
  --filename \
    https://raw.githubusercontent.com/knative/serving/{knative-serving-version}/third_party/kourier-latest/kourier.yaml
----
copyToClipboard::run-install-kourier[]

.Kourier pods
[source,bash,subs="+quotes,+attributes,+macros"]
----
watch kubectl get pods -n kourier-system
----

[source,bash,subs="+quotes,+attributes,+macros"]
----
NAME                                      READY   STATUS    RESTARTS   AGE
3scale-kourier-control-77459dcc76-56pkc   1/1     Running   0          55s
3scale-kourier-gateway-8645d88bf6-gvbf7   1/1     Running   0          56s
----


Now configure Knative serving to use Kourier as the ingress:

[#run-config-kn-kourier]
[source,bash,subs="+macros,+attributes"]
----
kubectl patch configmap/config-network \
  -n knative-serving \
  --type merge \
  -p '{"data":{"ingress.class":"kourier.ingress.networking.knative.dev"}}'
----
copyToClipboard::run-config-kn-kourier[]

**Install Knative Eventing** 

[#run-install-knative-eventing]
[source,bash,subs="+macros,+attributes"]
----
kubectl apply \
  --selector \
  networking.knative.dev/certificate-provider!=cert-manager \
  --filename \
  {knative-eventing-repo}/{knative-eventing-version}/eventing.yaml
----
copyToClipboard::run-install-knative-eventing[]

Like Knative Serving deployment, Knative Eventing deployment will also take few minutes to complete. You can watch `knative-eventing` namespace pods for live status, using the command:

.Knative eventing pods
[source,bash,subs="+quotes,+attributes,+macros"]
----
watch kubectl get pods -n knative-eventing
----

[source,bash,subs="+quotes,+attributes,+macros"]
----
NAME                                   READY   STATUS    RESTARTS   AGE
eventing-controller-69ffcc6f7d-9qb6z   1/1     Running   0          41s
eventing-webhook-6c56fcd86c-n6mzc      1/1     Running   0          41s
imc-controller-6bcf5957b5-5zpxd        1/1     Running   0          40s
imc-dispatcher-f59b7c57-qkqnq          1/1     Running   0          40s
sources-controller-8596684d7b-gkvc2    1/1     Running   0          41s
----

**Configuring Kubernetes namespace**

All the tutorial exercises will be deployed in namespace called `{tutorial-namespace}`:

[#setup-knative-tutorial-ns]
[source,bash,subs="+macros,+attributes"]
----
kubectl create namespace {tutorial-namespace}
----
copyToClipboard::setup-knative-tutorial-ns[]

[TIP]
=====
The https://github.com/ahmetb/kubens[kubens] utility installed as part of https://github.com/ahmetb/kubectx[kubectx] allows for easy switching between Kubernetes namespaces.

[#setup-knative-tutorial-kubens]
[source,bash,subs="+macros,+attributes"]
----
kubens {tutorial-namespace}
----
copyToClipboard::setup-knative-tutorial-kubens[]

=====

